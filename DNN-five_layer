import os
import torch
import numpy as np
import torchvision
import torch.nn.functional as F
from torchvision import transforms
from torch.utils.data import DataLoader
import csv
from tqdm import tqdm
import argparse
import pathlib
import random
from sklearn.model_selection import KFold  # 导入K折交叉验证库,对k组不同的数据进行训练减少方差结果
os.environ['CUDA_VISIBLE_DEVICES']='0'
device = torch.device("cuda:0") if torch.cuda.is_available() else torch.device("cpu")
#设计监测层的大小，分成10个区域，对各自区域求和
def detector_region(x):
    DETECTOR_POS = [
            (10, 20, 10, 20),
            (10, 20, 40, 50),
            (10, 20, 80, 90),
            (40,50, 10, 20),
            (40,50, 25,35),
            (40,50, 50, 65),
            (40,50, 80, 90),
            (80, 90, 10, 20),
            (80, 90, 40, 50),
            (80, 90, 80, 90)
    ]
    detectors_list = []
    full_int = x.sum(dim=(1, 2))
    for det_x0, det_x1, det_y0, det_y1 in DETECTOR_POS:
        detectors_list.append(
            (x[:, det_x0: det_x1 + 1, det_y0: det_y1 + 1].sum(dim=(1, 2)) / full_int).unsqueeze(-1))
    return torch.cat(detectors_list, dim=1)
#构建衍射层的函数
class DiffractiveLayer(torch.nn.Module):

    def __init__(self,  wl, N_pixels, pixel_size, dz,refractive_index,weight_decay):
        super(DiffractiveLayer, self).__init__()
        self.refractive_index=refractive_index
        wl_array=wl

        fx = np.fft.fftshift(np.fft.fftfreq(N_pixels, d = pixel_size))
        fy = np.fft.fftshift(np.fft.fftfreq(N_pixels, d = pixel_size))
        fxx, fyy = np.meshgrid(fx, fy)

        argument = (2 * np.pi)**2 * ((1. / wl_array) ** 2 - fxx ** 2 - fyy ** 2)

        #Calculate the propagating and the evanescent (complex) modes
        tmp = np.sqrt(np.abs(argument))
        kz = torch.tensor(np.where(argument >= 0, tmp, 1j*tmp*self.refractive_index))
        self.weight = torch.nn.Parameter(torch.exp(1j * kz * dz))
        self.weight_decay=weight_decay  #L2正则化系数
    def forward(self, E):
        # waves (batch, channels, 200, 200)
        loss=0
        fft_c = torch.fft.fft2(E)
        c = torch.fft.fftshift(fft_c)
        angular_spectrum = torch.fft.ifft2(torch.fft.ifftshift(c * self.weight))
        l2_regularization =self.weight_decay*torch.norm(self.weight,p=2)
        loss +=l2_regularization
        return angular_spectrum
class Diffractivelayer_air(torch.nn.Module):
    def __init__(self, wl, N_pixels, pixel_size, dz,weight_decay):
        super(Diffractivelayer_air, self).__init__()
        wl_array = wl
        fx = np.fft.fftshift(np.fft.fftfreq(N_pixels, d=pixel_size))
        fy = np.fft.fftshift(np.fft.fftfreq(N_pixels, d=pixel_size))
        fxx, fyy = np.meshgrid(fx, fy)
        argument = (2 * np.pi) ** 2 * ((1. / wl_array) ** 2 - fxx ** 2 - fyy ** 2)

        # Calculate the propagating and the evanescent (complex) modes
        tmp = np.sqrt(np.abs(argument))
        kz = torch.tensor(np.where(argument >= 0, tmp, 1j * tmp))
        self.weight = torch.nn.Parameter(torch.exp(1j * kz * dz))
        self.weight_decay = weight_decay  # L2正则化系数
    def forward(self, E):
        loss=0
        fft_c = torch.fft.fft2(E)
        c = torch.fft.fftshift(fft_c)
        angular_spectrum = torch.fft.ifft2(torch.fft.ifftshift(c * self.weight))
        l2_regularization =self.weight_decay*torch.norm(self.weight,p=2)
        loss +=l2_regularization
        return angular_spectrum
#创建神经网络
class Net(torch.nn.Module):
    def __init__(self,num_layers=5, wl=633e-9, N_pixels=100, pixel_size=3.8e-6, distance=1.1e-3,first_dis=10e-2,last_dis=5e-2,refractive_index=1.52,weight_decay=1e-3):
        super(Net,self).__init__()
        self.weight_decay=weight_decay
        self.phase = [torch.nn.Parameter(torch.from_numpy(2 * np.pi * np.random.random(size=(100,100)).astype('float64'))) for _ in range(num_layers)]
        #设置每个衍射层的权重，也就是我们需要去迭代更新的结果，这里的torch.nn.Parameter是指模型参数可以被优化，训练过程中使用梯度下降的方法
        for i in range(num_layers):
            self.register_parameter("phase" + "_" + str(i), self.phase[i])  #设置模型的注册参数，可训练
        self.first_diffractive_layer = Diffractivelayer_air(wl, N_pixels, pixel_size, first_dis,weight_decay)
        self.diffractiveLayer = torch.nn.ModuleList([DiffractiveLayer(wl, N_pixels, pixel_size, distance,refractive_index,weight_decay) for _ in range(num_layers)])  #设置衍射层的模型层列表
        self.last_diffractive_layer = Diffractivelayer_air(wl, N_pixels, pixel_size, last_dis,weight_decay)
         #交叉熵自带，对衍射层进行softmax激活，这里面需要考虑对应物理模型，是否对应于偏振片
    def forward(self,x):
        x=self.first_diffractive_layer(x)
        loss=0
        for index, layer in enumerate(self.diffractiveLayer):
            temp = layer(x)  #输入图案经过光衍射传播后的结果
            constr_phase=2*np.pi*torch.sigmoid(getattr(self,"phase" + "_" + str(index)))   #衍射层的相位_
            exp_j_phase=torch.exp(1j*constr_phase)    #
            x=temp*exp_j_phase      #经过衍射传播后与衍射层的乘积
            l2_regularization = self.weight_decay * torch.norm(exp_j_phase - 1, p=2)
            loss+=l2_regularization
        x=self.last_diffractive_layer(x) #经过最后一层衍射层与CCD的光衍射传播，这里面的距离distance可修改
        x_abs=torch.abs(x)**2
        output=detector_region(x_abs)
        return x_abs,torch.abs(output),loss
def main(args):
    args.batch_size = 200   #训练的batch_size
    args.num_epochs = 10  #设置epoch
    args.pixel_size=5e-6
    args.lr=1e-2
    N_pixels=100
    detector_pos = [
            (10, 20, 10, 20),
            (10, 20, 40, 50),
            (10, 20, 80, 90),
            (40,50, 10, 20),
            (40,50, 25,35),
            (40,50, 50, 65),
            (40,50, 80, 90),
            (80, 90, 10, 20),
            (80, 90, 40, 50),
            (80, 90, 80, 90)
    ]
    #下载mnist数据并且设置训练集，验证集
    transform = transforms.Compose([transforms.ToTensor(),transforms.Resize((84,84),antialias=True)])
    train_dataset = torchvision.datasets.MNIST("./data", train=True, transform=transform, download=True)
    k_folds=5
    kf=KFold(n_splits=k_folds,shuffle=True,random_state=42)
    model = Net()  # 导入搭建的神经模型
    model.to(device)  # 转到GPU
    criterion = torch.nn.MSELoss(reduction='sum').to(device)  # 设置损失函数crossEntropyLoss
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)  # 设置优化器
    for fold,(train_indices, val_indices) in enumerate(kf.split(train_dataset)):
        print(f'Fold {fold+1}/{k_folds}')
        train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)
        val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)

        train_dataloader = DataLoader(dataset=train_dataset, batch_size=args.batch_size, num_workers=4,
                                      sampler=train_sampler)
        val_dataloader = DataLoader(dataset=train_dataset, batch_size=args.batch_size, num_workers=4,
                                    sampler=val_sampler)
    ##

        #设置模型的保存地址，如果不存在地址，则新建
        if not os.path.exists(args.model_save_path):
            os.mkdir(args.model_save_path)
        #判断是否加载模型
        if args.whether_load_model:
            model.load_state_dict(torch.load(args.model_save_path + str(args.start_epoch) + args.model_name))
            #加载之前保存的模型参数
            print('Model : "' + args.model_save_path + str(args.start_epoch) + args.model_name + '" loaded.')
        else:
            if os.path.exists(args.result_record_path):
                os.remove(args.result_record_path)
            else:
                with open(args.result_record_path, 'w') as csvfile:
                    writer = csv.writer(csvfile)
                    writer.writerow(
                        ['Epoch', 'Train_Loss', "Train_Acc", 'Val_Loss', "Val_Acc", "LR"])

        labels_image_tensors = torch.zeros((10, N_pixels, N_pixels), device=device, dtype=torch.double)
        for ind, pos in enumerate(detector_pos):
            pos_l, pos_r, pos_u, pos_d = pos
            labels_image_tensors[ind, pos_l:pos_r, pos_u:pos_d] = 1
            labels_image_tensors[ind] = labels_image_tensors[ind] / labels_image_tensors[ind].sum()
        for epoch in range(args.start_epoch + 1, args.start_epoch + 1 + args.num_epochs):
            log = [epoch]
            model.train()   #模型训练
            train_len = 0.0
            train_running_counter = 0.0
            train_running_loss = 0.0
            padding=8
            tk0 = tqdm(train_dataloader, ncols=100, total=int(len(train_dataloader)))
            for train_iter, train_data_batch in enumerate(tk0):
                train_images = train_data_batch[0].to(device) # (2, 1, 28, 28) float32 1. 0.
                train_labels = train_data_batch[1].to(device)  # (1024, 10) int64 9 0
                train_images = F.pad(train_images,pad=(padding,padding,padding,padding))
                train_images = train_images.squeeze(dim=1)
                # train_labels = F.one_hot(train_labels, num_classes=10).float()
                det_labels=labels_image_tensors[train_labels]

                out_img,train_outputs,L2_loss = model(train_images.to(device))  #输出的是还未经过detection处理的结果
                # det_outputs=detector_region(train_outputs)*args.pixel_size**2  #最后的输出结果
                _,predicted =torch.max(train_outputs.data,1)
                train_running_counter+= (predicted==train_labels).sum().item()
                train_len += det_labels.size(0)
                full_img=out_img.sum(axis=(1,2))
                det_outputs=out_img/full_img[:,None,None]
                train_loss_ = criterion(det_outputs.to(device), det_labels.to(device))   #输出结果与label的比较
                #通过对训练集和标签样品最大值索引的比较，对元素进行求和，统计样品正确数目的数量
                loss =train_loss_+L2_loss
                train_running_loss += loss.item()  #统计样品损失函数和
                optimizer.zero_grad()  #模型参数梯度设置为0
                train_loss_.backward()   #反向传播计算损失函数中关于模型参数的梯度
                # threshold=0.1
                # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=threshold)
                # for param in model.parameters():
                #     if param.grad is not None:
                #         gradients = param.grad.data
                #         phase_diff = gradients[1:].angle() - gradients[:-1].angle()  # 计算相位差梯度
                #         clipped_phase_diff = torch.clamp(phase_diff, -threshold, threshold)  # 裁剪相位差梯度
                #         # 更新相位差梯度
                #         gradients[1:] = gradients[:-1] + torch.exp(1j * clipped_phase_diff)
                # optimizer.step()  #进行梯度下降步骤，优化模型

                train_loss = train_running_loss / train_len  #计算损失
                train_accuracy = train_running_counter / train_len  #计算正确值
                # tk0.set_description_str('Epoch {}/{} : Training'.format(epoch, args.start_epoch + 1 + args.num_epochs - 1))  #设置进度条的前置信息
                tk0.set_postfix({'Train_Loss': '{:.3f}'.format(train_loss), 'Train_Accuracy': '{:.3f}'.format(train_accuracy)}) #设置进度条的后缀信息
            log.append(train_loss)
            log.append(train_accuracy)
            ##验证信息
            with torch.no_grad():
                model.eval()
                val_len = 0.0
                val_running_counter = 0.0
                val_running_loss = 0.0
                tk1 = tqdm(val_dataloader, ncols=100, total=int(len(val_dataloader)))
                for val_iter, val_data_batch in enumerate(tk1):
                    val_images = val_data_batch[0].to(device)  # (64, 1, 200, 200) float32 1. 0.
                    val_labels = val_data_batch[1].to(device)  # (1024, 10) int64 9 0
                    det_val_labels=labels_image_tensors[val_labels]
                    val_images = F.pad(val_images,pad=(padding,padding,padding,padding))
                    val_images = val_images.squeeze(dim=1)
                    out_val_img,val_outputs,L2_loss = model(val_images.to(device))  # 输出的是还未经过detection处理的结果
                    _, predicted = torch.max(val_outputs.data, 1)
                    val_running_counter += (predicted == val_labels).sum().item()
                    val_len += det_val_labels.size(0)
                    full_img = out_val_img.sum(axis=(1, 2))
                    det_outputs = out_val_img / full_img[:, None, None]
                    val_loss_ = criterion(det_outputs.to(device), det_val_labels.to(device))  # 输出结果与label的比较
                    # 通过对训练集和标签样品最大值索引的比较，对元素进行求和，统计样品正确数目的数量
                    loss =L2_loss+val_loss_
                    val_running_loss += loss.item()  # 统计样品损失函数和

                    val_loss = val_running_loss / val_len
                    val_accuracy = val_running_counter / val_len
                    # tk1.set_description_str('Epoch {}/{} : Validating'.format(epoch, args.start_epoch + 1 + args.num_epochs - 1))
                    tk1.set_postfix({'Val_Loss': '{:.5f}'.format(val_loss), 'Val_Accuarcy': '{:.5f}'.format(val_accuracy)})

                log.append(val_loss)
                log.append(val_accuracy)
        torch.save(model.state_dict(), f"model_fold_400_1.1_{fold + 1}.pth")
        print('Model : "' + f"model_fold_{fold + 1}.pth" + '" saved.')
        with open(args.result_record_path, 'a', newline="") as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(log)

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    # 训练参数

    parser.add_argument('--seed', type=int, default=42)
    parser.add_argument('--whether-load-model', type=bool, default=False, help="是否加载模型继续训练")
    parser.add_argument('--start-epoch', type=int, default=0, help='从哪个epoch继续训练')
    # 数据和模型相关
    parser.add_argument('--model-name', type=str, default='v_model.pth')
    parser.add_argument('--model-save-path', type=str, default="./saved_model/")
    parser.add_argument('--result-record-path', type=pathlib.Path, default="./result.csv", help="数值结果记录路径")

    torch.backends.cudnn.benchmark = True
    args_ = parser.parse_args()
    random.seed(args_.seed)
    np.random.seed(args_.seed)
    torch.manual_seed(args_.seed)
    main(args_)
